{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRdisplay::display_html(\"\n",
    "<style>\n",
    ".output_png {\n",
    "        display: table-cell;\n",
    "        text-align: center;\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Datos - Introducción\n",
    "\n",
    "## Objetivos de la unidad\n",
    "- Conocer el proceso general de adquisición de conocimiento a partir de bases de datos. \n",
    "- Comprender las diferencias entre modelamiento fenomenológico y modelamiento a partir de datos.\n",
    "- Comprender los problemas de plantear hipótesis a partir de datos, sin contar con modelos fenomenológicos. \n",
    "- Comprender los problemas del compromiso sesgo-varianza y el principio de parsimonia.\n",
    "\n",
    "\n",
    "## Desde 13283 a 13222\n",
    "\n",
    "### ¿Qué aprendimos en Inferencia y Modelos Estadísticos\n",
    "1. Modelamiento\n",
    "2. Análisis estadístico\n",
    "3. Muestreo estadístico\n",
    "4. Estimación estadística\n",
    "5. Decisión estadística\n",
    "6. Estadística no paramétrica\n",
    "7. Análisis de varianza\n",
    "8. Regresión estadística\n",
    "\n",
    "\n",
    "### ¿Qué significa ciencia de datos?\n",
    "\n",
    "**Conceptos importantes**\n",
    "\n",
    "- **Datos:** Hechos o medidas que describen característicasde objetos, eventos o personas, es la materia prima de lacual se obtendrá la información.\n",
    "- **Información:** Datos procesados y presentados en formaadecuada, de interés para un observador en un tiempo determinado.\n",
    "- **Conocimiento:** Información procesada para emitir juicios que llevan a conclusiones.\n",
    "- **Meta-conocimiento:** Reglas  que  permiten  obtener conocimiento.\n",
    "\n",
    "\n",
    "Por lo cual la ciencia de datos busca extraer conocimiento a partir de datos (masivos). En la actualidad, se asocia el término *big data*, para explicitar la abundancia, generación y variedad de datos.\n",
    "\n",
    "### Obtención de Conocimientode Bases de Datos - *Knowledge Discovery in Database (KDD)*\n",
    "\n",
    "> “Proceso no trivial de identificación válido, novedoso, potencialmente útil y esencialmente entendible  de obtención de **patrones** de los datos”.\n",
    "\n",
    "En donde la obtención de patrones indica: relaciones, correlaciones, tendencias, descripción de eventos raros, etc.\n",
    "\n",
    "1. Establecer objetivos del KDD.\n",
    "2. Obtención de datos.\n",
    "3. Preprocesamiento: selección de datos, limpieza de datos (filtrado), enriquecimiento y codificación.\n",
    "4. Minería de datos\n",
    "\n",
    "\n",
    "### ¿Qué busca el aprendizaje automático?\n",
    "\n",
    "- Identificar grupos o anomalías\n",
    "- Clasificación\n",
    "- Predicción\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R como tu amigo para los datos\n",
    "\n",
    "> R es un entorno y lenguaje de programación con un enfoque al análisis estadístico. R nació como una reimplementación de software libre del lenguaje S, adicionado con soporte para alcance estático. Se trata de uno de los lenguajes de programación más utilizados en investigación científica, siendo además muy popular en los campos de aprendizaje automático (machine learning), minería de datos, investigación biomédica, bioinformática y matemáticas financieras. A esto contribuye la posibilidad de cargar diferentes bibliotecas o paquetes con funcionalidades de cálculo y graficación. [Wikipedia](https://es.wikipedia.org/wiki/R_%28lenguaje_de_programaci%C3%B3n%29)\n",
    "\n",
    "Para la asignatura trabajaremos con este hermoso lenguaje, por lo cual deben instalar R y RStudio (IDE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = c(\"area\", \"perimeter\", \"compactness\", \"length\", \"width\", \"AC\", \"lengthGroove\", \"class\")\n",
    "url = \"https://www.dl.dropboxusercontent.com/s/wrexlo5im3g5ioi/seeds_dataset.csv\"\n",
    "seeds = read.csv(url, header = F, sep=\",\", col.names = columns)\n",
    "seeds$class = factor(seeds$class, levels = c(1,2,3), labels = c(\"Kama\", \"Rosa\", \"Canadian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(seeds$perimeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd(seeds$perimeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var(seeds$perimeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(seeds$width, seeds$area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggpubr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas básicas \n",
    "\n",
    "### Regresión lineal\n",
    "\n",
    "**Regresión** consiste en ajustar un modelo parámetrico que sea capaz de predecir $y$ dado $x$.\n",
    "\n",
    "$$f_{\\theta}: y \\to x$$\n",
    "\n",
    "Entonces tenemos que:\n",
    "- $x$ variable independiente, entrada, característica, predictor\n",
    "- $y$ variable dependiente, salida, respuesta, objetivo\n",
    "- Tanto $x$ como $y$ son variables continuas\n",
    "- $\\theta$ son los parámetros del modelo.\n",
    "\n",
    "#### ¿Cuándo se habla de regresión lineal?\n",
    "\n",
    "- Cuando se tiene un conjunto de $M$ tuplas ($x_i$, $y_i$) $\\forall i = 1, 2, 3, ... , M$\n",
    "- Cuando se realiza un **ajuste** para encontrar el el valor óptimo de $\\theta$ en función de los datos.\n",
    "- Si $f_\\theta$ es lineal l en sus parámetros se puede escribir como un sistema lineal de $M$ ecuaciones.\n",
    "- Si el sistema es rectangular lo podemos resolver con Mínimos Cuadrados:\n",
    "\n",
    "$$ min_\\theta \\sum^{M}_{i=1} (y_i - f_\\theta (x_i))^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En la práctica:\n",
    "\n",
    "En la práctica se maneja:\n",
    "\n",
    "1. Hipótesis con parámetros $\\theta_i$.\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1x$$\n",
    "2. Escoger $\\theta_0$ y $\\theta_1$ que ajuste $h_\\theta(x)$lo mas cercano a $y$ para nuestro conjunto de ejemplos $(x, y)$, respecto a nuestra función de costos.\n",
    "\n",
    "$$J_{\\theta_0, \\theta_1} = min_\\theta \\sum^{M}_{i=1} (y_i - (\\theta_0 + \\theta_1x_i))^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_1 = function(x) { return(1.5 + 0 * x)}\n",
    "h_2 = function(x) { return(0 + 0.5 * x)}\n",
    "h_3 = function(x) { return(1 + 0.5 * x)}\n",
    "x = c(0:6)\n",
    "\n",
    "h = data.frame(x, \n",
    "               h_1 = h_1(x), \n",
    "               h_2 = h_2(x), \n",
    "               h_3 = h_3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=15, repr.plot.height=5)\n",
    "ggline(h, \n",
    "       \"x\", \n",
    "       y = c(\"h_1\", \"h_2\", \"h_3\"), \n",
    "       combine=T,  \n",
    "       ylim=c(0,4),  \n",
    "       xlim=c(0,6)\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene respectivamente:\n",
    "\n",
    "$$h_1(x) = 1.5 + 0x$$\n",
    "$$h_2(x) = 0 + 0.5x$$\n",
    "$$h_3(x) = 1 + 0.5x$$\n",
    "\n",
    "## Ejemplo: \n",
    "\n",
    "Si queremos buscar de que valor será el **área** de nuestras semillas con respecto al **ancho**, tendríamos que:\n",
    "\n",
    "- Las $M$ tuplas: 210\n",
    "- Identificar variable de entrada ($x$): ancho.\n",
    "- Identificar variable de salida ($y$): área.\n",
    "- Encontrar la recta que se ajuste a nuestros datos a partir $h(\\theta)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=15, repr.plot.height=10)\n",
    "ggscatter(seeds, \"width\", \"area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.seeds = lm(area ~ width, seeds)\n",
    "rl.seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(rl.seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area.predict.fome = -9.5212 + 7.4783 * seeds$width\n",
    "area.predict.bkn = predict(rl.seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(area.predict.fome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(area.predict.bkn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds.predictions = data.frame(\n",
    "    area = c(seeds$area, area.predict.fome), \n",
    "    width = c(seeds$width, seeds$width),\n",
    "    type = c(rep(\"real\", 210), rep(\"pred\", 210)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=15, repr.plot.height=10)\n",
    "ggscatter(seeds.predictions, \"width\", \"area\", color=\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggscatter(seeds, \n",
    "          \"width\", \n",
    "          \"area\", \n",
    "          add = \"reg.line\",\n",
    "          conf.int = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos lineales en sus parámetros y en sus entradas\n",
    "\n",
    "#### Recta\n",
    "\n",
    "Si $x$ es unidimensional $$ y =\\theta_0 + \\theta_1 x $$\n",
    "\n",
    "\n",
    "##### Plano\n",
    "\n",
    "Si $\\vec x =(x_1, x_2)$ es bidimensional $$ y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 $$\n",
    "\n",
    "#### Hiperplano\n",
    "\n",
    "Si $\\vec x = (x_1, x_2, \\ldots, x_d)$ es d-dimensional $$ y = \\theta_0 + \\sum_{k=1}^d \\theta_k x_k $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística\n",
    "\n",
    "El modelo de regresión logística surge del deseo de modelar las probabilidades posteriores de las clases $K$ a través de funciones lineales en $x$, mientras que al mismo tiempo se asegura de que sumen una y permanezcan en $[0, 1]$. Entonces consiste en un métoo para aprender una mapeo entre una o más **variables continuas** (atributos) hacia una **variable binaria** (objetivo).\n",
    "\n",
    "$$ y_i \\leftarrow f_\\theta(x_i) = \\mathcal{S} \\left(\\theta_0 + \\sum_{j=1}^M \\theta_j x_{ij}\\right) $$\n",
    "\n",
    "donde $\\mathcal{S}(z) = \\frac{1}{1+\\exp(-z)} \\in [0, 1]$ se conoce como función logística o sigmoid.\n",
    "\n",
    "Entonces tenemos que:\n",
    "- $x$ variable independiente, entrada, característica, predictor\n",
    "- $y$ variable dependiente, salida, respuesta, objetivo (etiqueta)\n",
    "- $\\theta$ son los parámetros del modelo.\n",
    "\n",
    "#### ¿Cuándo se habla de regresión logística?\n",
    "\n",
    "- Cuando se tiene un conjunto de $M$ tuplas ($x_i$, $y_i$) $\\forall i = 1, 2, 3, ... , M$\n",
    "- Cuando se realiza un **ajuste** para encontrar el el valor óptimo de $\\theta$ en función de los datos.\n",
    "\n",
    "#### ¿Qué función de costo es apropiada en este caso?\n",
    "\n",
    "Tipicamente se usa la **Entropía Cruzada Binaria**\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\sum_{i=1}^N  -y_i \\log( f_\\theta(\\vec x_i) ) - (1-y_i) \\log(1 - f_\\theta(\\vec x_i))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoide\n",
    "\n",
    "$$\\mathcal{S}(z) = \\frac{1}{1+\\exp(-z)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_1 = function(x, y) { return(-1 + 2*x*y)}\n",
    "h_2 = function(x, y) { return(0 + 3*x*y)}\n",
    "h_3 = function(x, y) { return(1 + -(4)*x*y)}\n",
    "x = c(-6:6)\n",
    "y = c(rep(0, 6), rep(1, 7))\n",
    "\n",
    "h = data.frame(x = x,\n",
    "               y = y,\n",
    "               h_1 = 1./(1 + exp(-h_1(x, y))), \n",
    "               h_2 = 1./(1 + exp(-h_2(x, y))), \n",
    "               h_3 = 1./(1 + exp(-h_3(x, y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=15, repr.plot.height=5)\n",
    "ggline(h, \n",
    "       \"x\", \n",
    "       y = c(\"h_1\", \"h_2\", \"h_3\"), \n",
    "       combine=T\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo:\n",
    "- Saber a que clase pertenecen las semillas respecto a su ancho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds.binary = seeds[seeds$class == \"Canadian\" | seeds$class == \"Rosa\", ]\n",
    "seeds.binary$class_ = as.integer(seeds.binary$class) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Esto es justo lo que no hay que hacer\n",
    "ggscatter(seeds.binary, \"width\", \"class_\", color=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog.seeds = glm(class ~ width, seeds, family = \"binomial\")\n",
    "rlog.seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(rlog.seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Métricas: Evaluando un clasificador binario\n",
    "\n",
    "La salida de este clasificador es un valor en el rango $[0, 1]$\n",
    "\n",
    "\n",
    "- True positives (TP): Es clase (1) y lo clasifico como (1)\n",
    "- True negative (TN): Es clase (0) y lo clasifico como (0)\n",
    "- False positives (FP): Es clase (0) y lo clasifico como (1): Error tipo I\n",
    "- False negative (FN): Es clase (1) y lo clasifico como (0): Error tipo II\n",
    "\n",
    "A partir de estas métricas se construye la tabla de confusión del clasificador\n",
    "\n",
    "|Real/Predicho|Positivo| Negativo |\n",
    "|-|-|-|\n",
    "| Positivo | TP | FP |\n",
    "| Negativo | FN | TN |\n",
    "\n",
    "En base a estas métricas se construyen otras \n",
    "$$ \\text{Recall} = \\frac{TP}{TP + FN} $$ \n",
    "\n",
    "\n",
    "\n",
    "> **TPR (Tasa de Verdaderos Positivos):** La proporción de positivos correctamente clasificados respecto al total de positivos. Tambien conocida como $sensitividad$.\n",
    "\n",
    "$$ \\text{FPR} = \\frac{FP}{TN + FP} = 1 - \\frac{TN}{TN + FP} $$\n",
    "\n",
    "\n",
    "> **FPR (Tasa de Falsos Positivos)**: La proporción de negativos incorrectamente clasificados respecto al total de negativos. También representada como $1 - especificidad$\n",
    "\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{TP+TN}{TP + FP + FN+ TN} $$\n",
    "\n",
    "> **Accuracy:** La proporción de ejemplos correctamente clasificados\n",
    "\n",
    "$$ \\text{f1-score} = \\frac{2*\\text{Recall}*\\text{Precision}}{\\text{Recall} + \\text{Precision}} $$\n",
    "\n",
    "> **f1-score:** Media armónica entre Recall y Precision asumiendo igual ponderación\n",
    "\n",
    "**Nota:** Si las clases son desbalanceadas entonces f1-score es más aconsejable que accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada\n",
    "\n",
    "Método para conocer como se comportará el el modelo en términos de predicción con datos futuros. \n",
    "\n",
    "\n",
    "> ... cross-validation typically estimates well only the expected prediction error. (Pág. 241. The Elements of Statistical Learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cv](https://4.bp.blogspot.com/-rtu5FnXZPBM/VFgRiSfR4aI/AAAAAAAABOA/SI2cawyRCuc/s1600/validacioncruzada_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Resumen y más\n",
    "\n",
    "Un modelo con más parámetros es más flexible pero también más complejo\n",
    "\n",
    "> Complejidad: grados de libertad de un modelo\n",
    "\n",
    "Un exceso de flexibilidad no es bueno. Podría ocurrir que el modelo se ajuste al ruido\n",
    "\n",
    "> Sobreajuste: Ocurre cuando el modelo \"memoriza\" los datos\n",
    "\n",
    "Cuando esto ocurre el modelo pierde capacidad de generalización\n",
    "\n",
    "> Generalización: Capacidad de predecir adecuadamente datos no usados en el ajuste\n",
    "\n",
    "Tres maneras de evitar el sobreajuste y mejorar la capacidad de generalización\n",
    "\n",
    "- Usar modelos de baja complejidad\n",
    "- Escoger la complejidad mediante pruebas de validación\n",
    "- Usar **regularización**\n",
    "\n",
    "####  Regularización\n",
    "\n",
    "Consiste en agregar una **penalización** adicional al problema\n",
    "\n",
    "El ejemplo clásico es pedir que la solución tenga norma mínima\n",
    "$$ \\min_x \\|Ax-b\\|_2^2 + \\lambda \\|x\\|_2^2 $$\n",
    "\n",
    "En este caso la solución es\n",
    "$$ \\hat x = (A^T A + \\lambda I)^{-1} A^T b $$\n",
    "\n",
    "que se conoce como **ridge regression** o **regularización de Tikhonov**\n",
    "\n",
    "$\\lambda$ es un **hiper-parámetro** del modelo y debe ser escogido por el usuario (usando validación).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas tipo PEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
